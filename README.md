# Pipeline de Dados Meta Graph API

[![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-2.7.3-017CEE?style=flat&logo=Apache%20Airflow&logoColor=white)](https://airflow.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.8%2B-3776AB?style=flat&logo=python&logoColor=white)](https://www.python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-316192?style=flat&logo=postgresql&logoColor=white)](https://www.postgresql.org/)
[![SQL Server](https://img.shields.io/badge/SQL%20Server-CC2927?style=flat&logo=microsoft-sql-server&logoColor=white)](https://www.microsoft.com/sql-server)

Pipeline de dados escal√°vel e pronto para produ√ß√£o usando Apache Airflow para extrair, transformar e carregar dados de publicidade da Meta Graph API (Facebook & Instagram) atrav√©s de m√∫ltiplas contas do Business Manager.

## Vis√£o Geral

Este projeto demonstra uma solu√ß√£o robusta de engenharia de dados para gerenciar dados de publicidade de m√∫ltiplas contas do Meta Business Manager. Apresenta:

- **Orquestra√ß√£o multi-conta** - Gerencia 10+ contas publicit√°rias com rota√ß√£o inteligente de tokens
- **Processamento paralelo** - Task groups para performance otimizada de extra√ß√£o
- **Arquitetura enterprise** - Separa√ß√£o de responsabilidades, gerenciamento de configura√ß√£o e tratamento de erros
- **Sincroniza√ß√£o de banco de dados** - Estrat√©gia dual-database (PostgreSQL para data lake, SQL Server para analytics)
- **Boas pr√°ticas de produ√ß√£o** - Configura√ß√£o baseada em vari√°veis de ambiente, logging completo, mecanismos de retry

## Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Apache Airflow DAG                         ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                        ‚îÇ
‚îÇ  ‚îÇ Task Group 1 ‚îÇ      ‚îÇ Task Group 2 ‚îÇ                        ‚îÇ
‚îÇ  ‚îÇ Contas 1-5   ‚îÇ  ‚Üí   ‚îÇ Contas 6-10  ‚îÇ   ‚Üí   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  (Paralelo)  ‚îÇ      ‚îÇ  (Paralelo)  ‚îÇ       ‚îÇ Sync SQL    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚Üì                                        ‚Üì
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ   PostgreSQL     ‚îÇ                    ‚îÇ   SQL Server     ‚îÇ
      ‚îÇ   (Data Lake)    ‚îÇ    ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê>        ‚îÇ   (Analytics)    ‚îÇ
      ‚îÇ                  ‚îÇ    Sync Views      ‚îÇ                  ‚îÇ
      ‚îÇ ‚Ä¢ Dados brutos   ‚îÇ                    ‚îÇ ‚Ä¢ Dados agregados‚îÇ
      ‚îÇ ‚Ä¢ Dados actions  ‚îÇ                    ‚îÇ ‚Ä¢ Views neg√≥cio  ‚îÇ
      ‚îÇ ‚Ä¢ Multi-contas   ‚îÇ                    ‚îÇ ‚Ä¢ Relat√≥rios     ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes Principais

1. **Orquestrador DAG** ([meta_graph_api_pipeline.py](dags/meta_graph_api_pipeline.py))
   - Agenda e coordena todas as tarefas
   - Gerencia execu√ß√£o paralela com task groups
   - Lida com retries e cen√°rios de falha

2. **Cliente Graph API** ([utils/graph_api.py](utils/graph_api.py))
   - Abstrai intera√ß√µes com Meta Graph API
   - Implementa pagina√ß√£o e rate limiting
   - Processa e transforma respostas da API

3. **Gerenciador de Banco de Dados** ([utils/database.py](utils/database.py))
   - Gerencia todas as opera√ß√µes de banco de dados
   - Implementa padr√£o upsert para consist√™ncia de dados
   - Gerencia sincroniza√ß√£o cross-database

4. **Camada de Configura√ß√£o** ([config/accounts_config.py](config/accounts_config.py))
   - Configura√ß√£o baseada em vari√°veis de ambiente
   - Gerenciamento multi-conta com rota√ß√£o de tokens
   - Valida√ß√£o e verifica√ß√£o de erros

## Funcionalidades

### Gerenciamento Multi-Conta
- **Configura√ß√£o din√¢mica de contas** via vari√°veis de ambiente
- **Rota√ß√£o inteligente de tokens** para distribuir limites de rate da API
- **Processamento paralelo** com task groups configur√°veis
- **Tabelas por conta** para isolamento e escalabilidade de dados

### Pipeline de Dados Robusto
- **Cargas incrementais** com per√≠odo de reten√ß√£o configur√°vel (padr√£o: 15 dias)
- **Opera√ß√µes upsert** para prevenir duplicatas
- **Tratamento de erros abrangente** com retries autom√°ticos
- **Gerenciamento de rate limit** com backoff exponencial

### Recursos Enterprise
- **Configura√ß√£o baseada em ambiente** - Sem credenciais hardcoded
- **Arquitetura modular** - Separa√ß√£o clara de responsabilidades
- **Logging abrangente** - Visibilidade completa da execu√ß√£o do pipeline
- **Sincroniza√ß√£o de banco de dados** - Propaga√ß√£o autom√°tica de dados
- **Design escal√°vel** - F√°cil adicionar novas contas ou fontes de dados

## Pr√©-requisitos

- Python 3.8+
- Apache Airflow 2.7.3+
- PostgreSQL 12+
- SQL Server 2019+ (ou Azure SQL Database)
- Conta(s) Meta Business Manager com acesso √† API

## üõ†Ô∏è Instala√ß√£o

### 1. Clonar o Reposit√≥rio

```bash
git clone https://github.com/seu-usuario/meta-ads-data-pipeline.git
cd meta-ads-data-pipeline
```

### 2. Criar Ambiente Virtual

```bash
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac
```

### 3. Instalar Depend√™ncias

```bash
pip install -r requirements.txt
```

### 4. Configurar Vari√°veis de Ambiente

Copie o arquivo de exemplo e configure com suas credenciais:

```bash
cp .env.example .env
```

Edite o `.env` com suas configura√ß√µes:

```bash
# Configura√ß√£o PostgreSQL
POSTGRES_HOST=seu-host-postgres
POSTGRES_PORT=5432
POSTGRES_USER=seu-usuario
POSTGRES_PASSWORD=sua-senha
POSTGRES_DATABASE=seu-database
POSTGRES_SCHEMA=seu-schema

# Configura√ß√£o SQL Server
SQLSERVER_HOST=seu-sqlserver.database.windows.net
SQLSERVER_PORT=1433
SQLSERVER_DATABASE=seu-database
SQLSERVER_USER=seu-usuario
SQLSERVER_PASSWORD=sua-senha
SQLSERVER_SCHEMA=graph

# Configura√ß√£o Meta Graph API
GRAPH_API_TOKENS=token1,token2,token3
META_ACCOUNTS=id_conta_1:bm_01,id_conta_2:bm_02,id_conta_3:bm_03

# Configura√ß√£o da API
GRAPH_API_VERSION=v19.0
DATA_RETENTION_DAYS=15
```

### 5. Configurar Banco de Dados

Crie as tabelas necess√°rias no PostgreSQL:

```sql
-- Criar schema
CREATE SCHEMA IF NOT EXISTS seu_schema;

-- Criar tabela de exemplo para ads
CREATE TABLE seu_schema.bm_01 (
    unique_id VARCHAR(32) PRIMARY KEY,
    account_id VARCHAR(50),
    account_name VARCHAR(255),
    campaign_id VARCHAR(50),
    campaign_name VARCHAR(255),
    campaign_status VARCHAR(50),
    adset_id VARCHAR(50),
    adset_name VARCHAR(255),
    ad_id VARCHAR(50),
    ad_name VARCHAR(255),
    objective VARCHAR(100),
    spend DECIMAL(10, 2),
    clicks INTEGER,
    inline_link_clicks INTEGER,
    impressions INTEGER,
    date DATE
);

-- Criar tabela de actions
CREATE TABLE seu_schema.bm_01_actions (
    account_id VARCHAR(50),
    ad_id VARCHAR(50),
    action_type VARCHAR(100),
    value INTEGER,
    date DATE
);

-- Criar views para consolida√ß√£o de dados
CREATE VIEW seu_schema.vw_graph_ads AS
SELECT * FROM seu_schema.bm_01
UNION ALL
SELECT * FROM seu_schema.bm_02
-- ... adicione todas as suas tabelas de contas
;
```

### 6. Inicializar Airflow

```bash
# Inicializar banco de dados do Airflow
airflow db init

# Criar usu√°rio admin
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com
```

## Uso

### Iniciar Airflow

```bash
# Iniciar web server (porta padr√£o 8080)
airflow webserver --port 8080

# Em outro terminal, iniciar o scheduler
airflow scheduler
```

### Acessar Interface do Airflow

Navegue para `http://localhost:8080` e fa√ßa login com suas credenciais.

### Habilitar a DAG

1. Encontre a DAG chamada `meta_graph_api_pipeline`
2. Alterne para "On"
3. A DAG executar√° conforme agendamento: **8:00, 14:00, 20:00 (Seg-S√°b)**

### Trigger Manual

Voc√™ pode disparar manualmente a DAG pela UI ou CLI:

```bash
airflow dags trigger meta_graph_api_pipeline
```

## üìä Fluxo de Dados

### Fase de Extra√ß√£o
1. DAG dispara task groups paralelos
2. Cada task busca dados de uma conta via Graph API
3. Dados incluem:
   - M√©tricas de performance de an√∫ncios (gasto, cliques, impress√µes)
   - Informa√ß√µes e status de campanhas
   - A√ß√µes e eventos de convers√£o
4. Dados s√£o validados e transformados

### Fase de Carregamento
1. Dados s√£o inseridos no PostgreSQL em tabelas espec√≠ficas por conta
2. Duplicatas s√£o prevenidas usando hash unique_id
3. Dados hist√≥ricos mantidos baseado na pol√≠tica de reten√ß√£o

### Fase de Sincroniza√ß√£o
1. Views do PostgreSQL agregam dados de todas as contas
2. Dados s√£o sincronizados para SQL Server para analytics
3. Registros antigos s√£o deletados antes de inserir novos
4. Threads paralelas otimizam transfer√™ncias de grandes volumes

## Configura√ß√£o

### Adicionar Novas Contas

Simplesmente atualize seu arquivo `.env`:

```bash
META_ACCOUNTS=contas_existentes,nova_conta_id:bm_11
GRAPH_API_TOKENS=tokens_existentes,novo_token
```

O pipeline descobre e processa automaticamente as novas contas.

### Ajustar Agendamento

Modifique o `SCHEDULE_INTERVAL` em [meta_graph_api_pipeline.py](dags/meta_graph_api_pipeline.py):

```python
SCHEDULE_INTERVAL = "0 8,14,20 * * 1-6"  # Formato cron
```

### Customizar Reten√ß√£o de Dados

Atualize o `.env`:

```bash
DATA_RETENTION_DAYS=30  # Buscar √∫ltimos 30 dias ao inv√©s de 15
```

## Boas Pr√°ticas Demonstradas

### Organiza√ß√£o de C√≥digo
-  **Design modular** - M√≥dulos separados para API, database e configura√ß√£o
-  **Princ√≠pio DRY** - Fun√ß√µes e classes reutiliz√°veis
-  **Nomenclatura clara** - C√≥digo auto-documentado com nomes descritivos

### Gerenciamento de Configura√ß√£o
-  **Vari√°veis de ambiente** - Sem credenciais hardcoded
-  **`.env.example`** - Template para f√°cil configura√ß√£o
-  **Valida√ß√£o** - Verifica√ß√µes de configura√ß√£o antes da execu√ß√£o

### Tratamento de Erros
-  **L√≥gica de retry** - Retries autom√°ticos com backoff exponencial
-  **Rate limiting** - Respeita limites da API
-  **Logging abrangente** - Visibilidade completa da execu√ß√£o
-  **Degrada√ß√£o gradual** - Continua processando outras contas em caso de falha

### Opera√ß√µes de Banco de Dados
-  **Padr√£o upsert** - Previne duplicatas
-  **Processamento em lote** - Inser√ß√µes bulk eficientes
-  **Gerenciamento de transa√ß√µes** - Consist√™ncia de dados
-  **Connection pooling** - Uso otimizado de recursos

### Pronto para Produ√ß√£o
-  **Type hints** - Melhor suporte de IDE e documenta√ß√£o
-  **Docstrings** - Documenta√ß√£o clara de fun√ß√µes
-  **Logging** - Visibilidade de execu√ß√£o
-  **Estrutura de testes** - Pronto para testes unit√°rios

## Estrutura do Projeto

```
meta-ads-data-pipeline/
‚îú‚îÄ‚îÄ dags/
‚îÇ   ‚îú‚îÄ‚îÄ meta_graph_api_pipeline.py      # Defini√ß√£o principal da DAG
‚îÇ   ‚îî‚îÄ‚îÄ grax_midia_facebook_graph_api_new.py  # Legacy (refer√™ncia)
‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py                      # Opera√ß√µes de banco de dados
‚îÇ   ‚îî‚îÄ‚îÄ graph_api.py                     # Cliente Graph API
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ accounts_config.py               # Gerenciamento de contas
‚îú‚îÄ‚îÄ tests/                               # Testes unit√°rios (a adicionar)
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ ARCHITECTURE.md                  # Arquitetura detalhada
‚îÇ   ‚îî‚îÄ‚îÄ GIT_WORKFLOW.md                  # Guia de workflow Git
‚îú‚îÄ‚îÄ .env.example                         # Template de ambiente
‚îú‚îÄ‚îÄ .gitignore                           # Regras de ignore do Git
‚îú‚îÄ‚îÄ requirements.txt                     # Depend√™ncias Python
‚îî‚îÄ‚îÄ README.md                            # Este arquivo
```

## Documenta√ß√£o Adicional

- [**Detalhes da Arquitetura**](docs/ARCHITECTURE.md) - Arquitetura t√©cnica aprofundada
- [**Workflow Git**](docs/GIT_WORKFLOW.md) - Estrat√©gia de branches e diretrizes de commit
- [**Guia de Setup**](SETUP_GUIDE.md) - Instru√ß√µes detalhadas de instala√ß√£o

## Licen√ßa

Este projeto √© para fins de demonstra√ß√£o de portf√≥lio.

## Autor

**Projeto de Portf√≥lio - Engenharia de Dados**

Demonstrando expertise em:
- Orquestra√ß√£o com Apache Airflow
- Integra√ß√£o de APIs e extra√ß√£o de dados
- Arquitetura multi-database
- Desenvolvimento Python pronto para produ√ß√£o
- Boas pr√°ticas de engenharia de dados
---

## Sobre Este Projeto

Este pipeline resolve um problema real de engenharia de dados: **como gerenciar e processar dados de m√∫ltiplas contas publicit√°rias de forma escal√°vel, eficiente e confi√°vel**.

### Problema Resolvido

Empresas que gerenciam m√∫ltiplas contas do Meta Business Manager enfrentam desafios como:
- Coleta manual de dados de m√∫ltiplas contas
- Rate limits da API
- Inconsist√™ncia de dados
- Falta de hist√≥rico consolidado
- Processos n√£o escal√°veis

### Solu√ß√£o Implementada

Este pipeline automatiza completamente o processo, oferecendo:
- Extra√ß√£o autom√°tica de 10+ contas simultaneamente
- Rota√ß√£o inteligente de tokens para otimizar rate limits
- Dados consolidados em data lake (PostgreSQL)
- Camada anal√≠tica pronta para BI (SQL Server)
- Agendamento autom√°tico (3x por dia)
- Tratamento robusto de erros e retries
- Escal√°vel para centenas de contas

### Impacto

-  **Economia de tempo**: Horas de trabalho manual ‚Üí Autom√°tico
-  **Qualidade de dados**: Dados consistentes e validados
-  **Escalabilidade**: F√°cil adicionar novas contas
-  **Confiabilidade**: Retry autom√°tico, logging completo
-  **Insights**: Dados prontos para an√°lise e BI

# meta-ads-airflow-pipeline
